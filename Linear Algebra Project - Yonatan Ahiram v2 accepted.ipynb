{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\t  \n",
    "Hi, my name is Dmitry and I will be reviewing your project.\n",
    "  \n",
    "You can find my comments in colored markdown cells:\n",
    "  \n",
    "<div class=\"alert alert-success\">\n",
    "  If everything is done successfully.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-warning\">\n",
    "  If I have some (optional) suggestions, or questions to think about, or general comments.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-danger\">\n",
    "  If a section requires some corrections. Work can't be accepted with red comments.\n",
    "</div>\n",
    "  \n",
    "Please don't remove my comments, as it will make further review iterations much harder for me.\n",
    "  \n",
    "Feel free to reply to my comments or ask questions using the following template:\n",
    "  \n",
    "<div class=\"alert alert-info\">\n",
    "  For your comments and questions.\n",
    "</div>\n",
    "  \n",
    "First of all, thank you for turning in the project! You did a great job overall, there's just one small correction needed in the proof, but it should be very straightforward. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  Hi Dmitry, thank you for reviewing my project :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V2</b>\n",
    "\t  \n",
    "You're welcome! The proof is fixed, so the project is accepted now. Keep up the good work on the next sprint! :)\n",
    "\t  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sure Tomorrow insurance company wants to solve several tasks with the help of Machine Learning and you are asked to evaluate that possibility.\n",
    "\n",
    "- Task 1: Find customers who are similar to a given customer. This will help the company's agents with marketing.\n",
    "- Task 2: Predict whether a new customer is likely to receive an insurance benefit. Can a prediction model do better than a dummy model?\n",
    "- Task 3: Predict the number of insurance benefits a new customer is likely to receive using a linear regression model.\n",
    "- Task 4: Protect clients' personal data without breaking the model from the previous task. It's necessary to develop a data transformation algorithm that would make it hard to recover personal information if the data fell into the wrong hands. This is called data masking, or data obfuscation. But the data should be protected in such a way that the quality of machine learning models doesn't suffer. You don't need to pick the best model, just prove that the algorithm works correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Exploration\n",
    "\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.2 MB 134 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.4.1)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.0.1 threadpoolctl-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and conduct a basic check that it's free from obvious issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/insurance_us.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rename the colums to make the code look more consistent with its style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>49700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>51700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age   income  family_members  insurance_benefits\n",
       "0       1  41.0  49600.0               1                   0\n",
       "1       0  46.0  38000.0               1                   1\n",
       "2       0  29.0  21000.0               0                   0\n",
       "3       0  21.0  41700.0               2                   0\n",
       "4       1  28.0  26100.0               0                   0\n",
       "5       1  43.0  41000.0               2                   1\n",
       "6       1  39.0  39700.0               2                   0\n",
       "7       1  25.0  38600.0               4                   0\n",
       "8       1  36.0  49700.0               1                   0\n",
       "9       1  32.0  51700.0               1                   0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      "gender                5000 non-null int64\n",
      "age                   5000 non-null float64\n",
      "income                5000 non-null float64\n",
      "family_members        5000 non-null int64\n",
      "insurance_benefits    5000 non-null int64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we may want to fix the age type (from float to int) though this is not critical\n",
    "\n",
    "# write your conversion here if you choose:\n",
    "df.age = df.age.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      "gender                5000 non-null int64\n",
      "age                   5000 non-null int32\n",
      "income                5000 non-null float64\n",
      "family_members        5000 non-null int64\n",
      "insurance_benefits    5000 non-null int64\n",
      "dtypes: float64(1), int32(1), int64(3)\n",
      "memory usage: 175.9 KB\n"
     ]
    }
   ],
   "source": [
    "# check to see that the conversion was successful\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>30.952800</td>\n",
       "      <td>39916.360000</td>\n",
       "      <td>1.194200</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.500049</td>\n",
       "      <td>8.440807</td>\n",
       "      <td>9900.083569</td>\n",
       "      <td>1.091387</td>\n",
       "      <td>0.463183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>33300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>46600.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>79000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender          age        income  family_members  \\\n",
       "count  5000.000000  5000.000000   5000.000000     5000.000000   \n",
       "mean      0.499000    30.952800  39916.360000        1.194200   \n",
       "std       0.500049     8.440807   9900.083569        1.091387   \n",
       "min       0.000000    18.000000   5300.000000        0.000000   \n",
       "25%       0.000000    24.000000  33300.000000        0.000000   \n",
       "50%       0.000000    30.000000  40200.000000        1.000000   \n",
       "75%       1.000000    37.000000  46600.000000        2.000000   \n",
       "max       1.000000    65.000000  79000.000000        6.000000   \n",
       "\n",
       "       insurance_benefits  \n",
       "count         5000.000000  \n",
       "mean             0.148000  \n",
       "std              0.463183  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              0.000000  \n",
       "max              5.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now have a look at the data's descriptive statistics. \n",
    "# Does everything look okay?\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data isn't balanced. More than 75% of the customers didn't recieve any insurance benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check whether there are certain groups of customers by looking at the pair plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.pairplot(df, kind='hist')\n",
    "g.fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it is a bit difficult to spot obvious groups (clusters) as it is difficult to combine several variables simultaneously (to analyze multivariate distributions). That's where LA and ML can be quite handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. Similar Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the language of ML, it is necessary to develop a procedure that returns k nearest neighbors (objects) for a given object based on the distance between the objects.\n",
    "\n",
    "You may want to review the following lessons (chapter -> lesson)\n",
    "- Distance Between Vectors -> Euclidean Distance\n",
    "- Distance Between Vectors -> Manhattan Distance\n",
    "\n",
    "To solve the task, we can try different distance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that returns k nearest neighbors for an $n^{th}$ object based on a specified distance metric. The number of received insurance benefits should not be taken into account for this task. \n",
    "\n",
    "You can use a ready implementation of the kNN algorithm from scikit-learn (check [the link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)) or use your own.\n",
    "\n",
    "Test it for four combination of two cases\n",
    "- Scaling\n",
    "  - the data is not scaled\n",
    "  - the data is scaled with the [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html) scaler\n",
    "- Distance Metrics\n",
    "  - Euclidean\n",
    "  - Manhattan\n",
    "\n",
    "Answer these questions:\n",
    "- Does the data being not scaled affect the kNN algorithm? If so, how does that appear?\n",
    "- How similar are the results using the Manhattan distance metric (regardless of the scaling)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_knn(df, n, k, metric):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Returns k nearest neighbors\n",
    "\n",
    "#     :param df: pandas DataFrame used to find similar objects within\n",
    "#     :param n: object no for which the nearest neighbours are looked for\n",
    "#     :param k: the number of the nearest neighbours to return\n",
    "#     :param metric: name of distance metric\n",
    "#     \"\"\"\n",
    "\n",
    "#     nbrs = # <your code here> \n",
    "#     nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)\n",
    "    \n",
    "#     df_res = pd.concat([\n",
    "#         df.iloc[nbrs_indices[0]], \n",
    "#         pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])\n",
    "#         ], axis=1)\n",
    "    \n",
    "#     return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']\n",
    "\n",
    "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.550633</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.513924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.182278</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.583544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.612658</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  insurance_benefits\n",
       "2156     1.0  0.353846  0.550633        0.166667                   0\n",
       "181      0.0  0.692308  0.513924        0.000000                   1\n",
       "1431     0.0  0.292308  0.182278        0.333333                   0\n",
       "1270     0.0  0.538462  0.583544        0.000000                   0\n",
       "633      0.0  0.676923  0.612658        0.500000                   1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get similar records for a given one for every combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0e+00, 2.2e+01, 8.0e+04, 3.0e+00, 0.0e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point = np.array([[1, 22.0, 80000, 3, 0]])\n",
    "point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1000.18098362, 4800.0186458 , 5200.00326923, 8400.00869047,\n",
       "         8600.00145349]]),\n",
       " array([[3255, 4512, 4360, 3328, 2193]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = NearestNeighbors() \n",
    "knn.fit(df)\n",
    "\n",
    "n_array = knn.kneighbors(point)\n",
    "n_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151864.1480378522"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = []\n",
    "\n",
    "for i in range(len(n_array)):\n",
    "    dist = distance.euclidean(n_array[i], point)\n",
    "    distances.append(dist)\n",
    "    \n",
    "unscaled_euclidean_dists = sum(distances)\n",
    "unscaled_euclidean_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186476.2065041498"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = []\n",
    "\n",
    "for i in range(len(n_array)):\n",
    "    dist = distance.cityblock(n_array[i], point)\n",
    "    distances.append(dist)\n",
    "    \n",
    "unscaled_manhattan_dists = sum(distances)\n",
    "unscaled_manhattan_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.63076923, 0.6278481 , 0.16666667, 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point = df_scaled.head(1).values\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.00632911, 0.01775386, 0.02962447, 0.03164557]]),\n",
       " array([[   0, 2689,  133, 1567, 2103]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = NearestNeighbors() \n",
    "knn.fit(df_scaled)\n",
    "\n",
    "n_array = knn.kneighbors(point)\n",
    "n_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3759.3168187810084"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = []\n",
    "\n",
    "for i in range(len(n_array)):\n",
    "    dist = distance.euclidean(n_array[i], point)\n",
    "    distances.append(dist)\n",
    "    \n",
    "scaled_euclidean_dists = sum(distances)\n",
    "scaled_euclidean_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6493.9779381267535"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = []\n",
    "\n",
    "for i in range(len(n_array)):\n",
    "    dist = distance.cityblock(n_array[i], point)\n",
    "    distances.append(dist)\n",
    "    \n",
    "scaled_manhattan_dists = sum(distances)\n",
    "scaled_manhattan_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers to the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does the data being not scaled affect the kNN algorithm? If so, how does that appear?** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled distances ratio: 81.44% \n",
      "Scaled distances ratio: 57.89%\n"
     ]
    }
   ],
   "source": [
    "scaled_dists_ratio = scaled_euclidean_dists / scaled_manhattan_dists\n",
    "unscaled_dists_ratio = unscaled_euclidean_dists / unscaled_manhattan_dists\n",
    "\n",
    "print('Unscaled distances ratio: {:.2%} \\nScaled distances ratio: {:.2%}'.format(unscaled_dists_ratio, scaled_dists_ratio))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data being not scaled does affect the kNN algorithm. As the values of our point from are bigger than its neighbors the distance increases as well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How similar are the results using the Manhattan distance metric (regardless of the scaling)?** \n",
    "\n",
    "As expected, the results of the Manhattan distance metric are much bigger than the euclidean distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\t  \n",
    "Sure, but the more interesting difference about scaled vs unscaled data is that if some feature has a much bigger scale than others it dominates the distance metric on unscaled data (in this case it is income), and the other features are basically disregarded. So distance-based algorithms like kNN are very sensitive to feature scales.\n",
    "    \n",
    "It would be nice if you printed the k nearest neighbors of some example (you can just take neighbors of the 0th row) with euclidean/manhattan distance on scaled and unscaled data to see this for yourself.\n",
    "\t  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2. Is Customer Likely to Receive Insurance Benefit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of machine learning we can look at this like a binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `insurance_benefits` being more than zero as the target, evaluate whether the kNN classification approach can do better than a dummy model.\n",
    "\n",
    "Instructions:\n",
    "- Build a KNN-based classifier and measure its quality with the F1 metric for k=1..10 for both the original data and the scaled one. That'd be interesting to see how k may influece the evaluation metric, and whether scaling the data makes any difference. You can use a ready implemention of the kNN classification algorithm from scikit-learn (check [the link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) or use your own.\n",
    "- Build the dummy model which is just random for this case. It should return \"1\" with some probability. Let's test the model with four probability values: 0, the probability of paying any insurance benefit, 0.5, 1.\n",
    "\n",
    "The probability of paying any insurance benefit can be defined as\n",
    "\n",
    "$$\n",
    "P\\{\\text{insurance benefit received}\\}=\\frac{\\text{number of clients received any insurance benefit}}{\\text{total number of clients}}.\n",
    "$$\n",
    "\n",
    "Split the whole data in the 70:30 proportion for the training/testing parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>insurance_benefits_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age   income  family_members  insurance_benefits  \\\n",
       "0       1   41  49600.0               1                   0   \n",
       "\n",
       "   insurance_benefits_received  \n",
       "0                          0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>insurance_benefits_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.627848</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender       age    income  family_members  insurance_benefits  \\\n",
       "0     1.0  0.630769  0.627848        0.166667                   0   \n",
       "\n",
       "   insurance_benefits_received  \n",
       "0                          0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the target\n",
    "\n",
    "df.loc[df['insurance_benefits'] > 0, 'insurance_benefits_received'] = 1\n",
    "df.loc[df['insurance_benefits'] == 0, 'insurance_benefits_received'] = 0\n",
    "display(df.head(1))\n",
    "\n",
    "df_scaled.loc[df['insurance_benefits'] > 0, 'insurance_benefits_received'] = 1\n",
    "df_scaled.loc[df['insurance_benefits'] == 0, 'insurance_benefits_received'] = 0\n",
    "display(df_scaled.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    88.72\n",
       "1.0    11.28\n",
       "Name: insurance_benefits_received, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check for the class imbalance with value_counts()\n",
    "value_counts_series = df.insurance_benefits_received.value_counts()\n",
    "display(value_counts_series/len(df) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data isn't balaced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(y_true, y_pred):\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "    print(f'F1: {f1_score:.2f}')\n",
    "    \n",
    "# if you have an issue with the following line, restart the kernel and run the notebook again\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print('Confusion Matrix')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating output of a random model\n",
    "\n",
    "def rnd_model_predict(P, size, seed=42):\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    return rng.binomial(n=1, p=P, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability: 0.00\n",
      "F1: 0.00\n",
      "Confusion Matrix\n",
      "[[0.8872 0.    ]\n",
      " [0.1128 0.    ]]\n",
      "\n",
      "The probability: 0.11\n",
      "F1: 0.12\n",
      "Confusion Matrix\n",
      "[[0.7914 0.0958]\n",
      " [0.0994 0.0134]]\n",
      "\n",
      "The probability: 0.50\n",
      "F1: 0.20\n",
      "Confusion Matrix\n",
      "[[0.456  0.4312]\n",
      " [0.053  0.0598]]\n",
      "\n",
      "The probability: 1.00\n",
      "F1: 0.20\n",
      "Confusion Matrix\n",
      "[[0.     0.8872]\n",
      " [0.     0.1128]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for P in [0, df['insurance_benefits_received'].sum() / len(df), 0.5, 1]:\n",
    "\n",
    "    print(f'The probability: {P:.2f}')\n",
    "    y_pred_rnd = rnd_model_predict(P, len(df)) \n",
    "        \n",
    "    eval_classifier(df['insurance_benefits_received'], y_pred_rnd)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the random model, as the probabilty goes up, the F1 goes up. Maximum F1 is 0.2 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.insurance_benefits_received\n",
    "features = df.drop('insurance_benefits_received', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k neighbors = 1:\n",
      "F1: 0.66\n",
      "Confusion Matrix\n",
      "[[0.87666667 0.016     ]\n",
      " [0.04666667 0.06066667]]\n",
      "\n",
      "k neighbors = 2:\n",
      "F1: 0.38\n",
      "Confusion Matrix\n",
      "[[0.89066667 0.002     ]\n",
      " [0.08133333 0.026     ]]\n",
      "\n",
      "k neighbors = 3:\n",
      "F1: 0.39\n",
      "Confusion Matrix\n",
      "[[0.88466667 0.008     ]\n",
      " [0.07933333 0.028     ]]\n",
      "\n",
      "k neighbors = 4:\n",
      "F1: 0.16\n",
      "Confusion Matrix\n",
      "[[0.88933333 0.00333333]\n",
      " [0.098      0.00933333]]\n",
      "\n",
      "k neighbors = 5:\n",
      "F1: 0.17\n",
      "Confusion Matrix\n",
      "[[0.884      0.00866667]\n",
      " [0.09666667 0.01066667]]\n",
      "\n",
      "k neighbors = 6:\n",
      "F1: 0.09\n",
      "Confusion Matrix\n",
      "[[8.92000000e-01 6.66666667e-04]\n",
      " [1.02000000e-01 5.33333333e-03]]\n",
      "\n",
      "k neighbors = 7:\n",
      "F1: 0.10\n",
      "Confusion Matrix\n",
      "[[0.89133333 0.00133333]\n",
      " [0.10133333 0.006     ]]\n",
      "\n",
      "k neighbors = 8:\n",
      "F1: 0.02\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.106      0.00133333]]\n",
      "\n",
      "k neighbors = 9:\n",
      "F1: 0.04\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.10533333 0.002     ]]\n",
      "\n",
      "k neighbors = 10:\n",
      "F1: 0.04\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.10533333 0.002     ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1, 11):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(features_train, target_train)\n",
    "    predictions = neigh.predict(features_test)\n",
    "    print('k neighbors = {}:'.format(k))\n",
    "    eval_classifier(target_test, predictions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the unscaled data, the best F1 score is when k=1 (0.66) and decreases as k increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_scaled.insurance_benefits_received\n",
    "features = df_scaled.drop('insurance_benefits_received', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k neighbors = 1:\n",
      "F1: 1.00\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.         0.10733333]]\n",
      "\n",
      "k neighbors = 2:\n",
      "F1: 1.00\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.         0.10733333]]\n",
      "\n",
      "k neighbors = 3:\n",
      "F1: 1.00\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.         0.10733333]]\n",
      "\n",
      "k neighbors = 4:\n",
      "F1: 1.00\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.         0.10733333]]\n",
      "\n",
      "k neighbors = 5:\n",
      "F1: 1.00\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.         0.10733333]]\n",
      "\n",
      "k neighbors = 6:\n",
      "F1: 1.00\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.         0.10733333]]\n",
      "\n",
      "k neighbors = 7:\n",
      "F1: 1.00\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.         0.10733333]]\n",
      "\n",
      "k neighbors = 8:\n",
      "F1: 1.00\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.         0.10733333]]\n",
      "\n",
      "k neighbors = 9:\n",
      "F1: 1.00\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.         0.10733333]]\n",
      "\n",
      "k neighbors = 10:\n",
      "F1: 1.00\n",
      "Confusion Matrix\n",
      "[[0.89266667 0.        ]\n",
      " [0.         0.10733333]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1, 11):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(features_train, target_train)\n",
    "    predictions = neigh.predict(features_test)\n",
    "    print('k neighbors = {}:'.format(k))\n",
    "    eval_classifier(target_test, predictions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the scaled data, F1 score is 1, no matter what the value of k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "The kNN classification approach does better than the dummy model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\t  \n",
    "Yes, but more improtantly, you confirmed that kNN is very sensitive to scaling\n",
    "\t  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3. Regression (with Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `insurance_benefits` as the target, evaluate what RMSE would be for a Linear Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build your own implementation of LR. For that, recall how the linear regression task's solution is formulated in terms of LA. Check RMSE for both the original data and the scaled one. Can you see any difference in RMSE between these two cases?\n",
    "\n",
    "Let's denote\n",
    "- $X$ — feature matrix, each row is a case, each column is a feature, the first column consists of unities\n",
    "- $y$ — target (a vector)\n",
    "- $\\hat{y}$ — estimated tagret (a vector)\n",
    "- $w$ — weight vector\n",
    "\n",
    "The task of linear regression in the language of matrices can be formulated as\n",
    "\n",
    "$$\n",
    "y = Xw\n",
    "$$\n",
    "\n",
    "The training objective then is to find such $w$ that it would minimize the L2-distance (MSE) between $Xw$ and $y$:\n",
    "\n",
    "$$\n",
    "\\min_w d_2(Xw, y) \\quad \\text{or} \\quad \\min_w \\text{MSE}(Xw, y)\n",
    "$$\n",
    "\n",
    "It appears that there is analytical solution for the above:\n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "The formula above can be used to find the weights $w$ and the latter can be used to calculate predicted values\n",
    "\n",
    "$$\n",
    "\\hat{y} = X_{val}w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the whole data in the 70:30 proportion for the training/validation parts. Use the RMSE metric for the model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # adding the unities\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        w = np.linalg.inv(X2.T.dot(X2)).dot(X2.T).dot(y)\n",
    "        self.weights = w[1:]\n",
    "        self.weights0 = w[0]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        # adding the unities\n",
    "        #X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        y_pred = X.dot(self.weights) + self.weights0\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\t  \n",
    "Linear regression was implemented correctly\n",
    "\t  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regressor(y_true, y_pred):\n",
    "    \n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'RMSE: {rmse:.2f}')\n",
    "    r2_score = math.sqrt(abs(sklearn.metrics.r2_score(y_true, y_pred)))\n",
    "    print(f'R2: {r2_score:.2f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.57495491e-02  1.64272726e-02 -2.60743659e-07 -1.16902127e-02]\n",
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.32372069  0.01642727 -0.02059875 -0.07014128]\n",
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X = df_scaled[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df_scaled['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both RMSE and R2 scores are the same. It makes sense in Linear Regression, since the scaling keeps the proportions of the data, thus we got the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\t  \n",
    "Not sure what you mean by 'keeps proportions of the data', I don't think that's true. Although the result that linear regression is not sensitive to scaling is correct.\n",
    "    \n",
    "\t  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4. Obfuscating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It best to obfuscate data by multiplying the numerical features (remember, they can be seen as the matrix $X$) by an invertible matrix $P$. \n",
    "\n",
    "$$\n",
    "X' = X \\times P\n",
    "$$\n",
    "\n",
    "Try to do that and check how the features' values will look like after the transformation. By the way, the intertible property is important here so make sure that $P$ is indeed invertible.\n",
    "\n",
    "You may want to review the 'Matrices and Matrix Operations -> Matrix Mupliplication' lesson to recall the rule of matrix multiplication and its implementation with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_info_column_list = ['gender', 'age', 'income', 'family_members']\n",
    "df_pn = df[personal_info_column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pn.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a random matrix $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X.shape[1], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the matrix $P$ is invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  4.31984031e-18, -2.78054126e-16,\n",
       "        -2.57000677e-16],\n",
       "       [ 6.08293605e-17,  1.00000000e+00, -6.90868844e-17,\n",
       "        -1.63138745e-16],\n",
       "       [-5.61258920e-17,  3.19494738e-16,  1.00000000e+00,\n",
       "         1.64271755e-18],\n",
       "       [ 2.25584045e-18, -1.89983786e-18,  4.42459684e-17,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(P)@P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.85130588e-16, -2.97856902e-16,\n",
       "        -3.91584367e-17],\n",
       "       [ 6.23834470e-17,  1.00000000e+00, -7.10568689e-17,\n",
       "         8.24459807e-17],\n",
       "       [ 1.03941594e-17,  2.27454503e-17,  1.00000000e+00,\n",
       "        -5.77784356e-17],\n",
       "       [-1.02697151e-16, -1.69379178e-16, -2.49945035e-17,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P@np.linalg.inv(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix 𝑃 is invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you guess the customers' ages or income after the transformation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6359.71527314, 22380.40467609, 18424.09074184, 46000.69669016],\n",
       "       [ 4873.29406479, 17160.36702982, 14125.78076133, 35253.45577301],\n",
       "       [ 2693.11742928,  9486.397744  ,  7808.83156024, 19484.86063067],\n",
       "       ...,\n",
       "       [ 4346.2234249 , 15289.24126492, 12586.16264392, 31433.50888552],\n",
       "       [ 4194.09324155, 14751.9910242 , 12144.02930637, 30323.88763426],\n",
       "       [ 5205.46827354, 18314.24814446, 15077.01370762, 37649.59295455]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_X = X@P\n",
    "trans_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you recover the original data from $X'$ if you know $P$? Try to check that with calculations by moving $P$ from the right side of the formula above to the left one. The rules of matrix multiplcation are really helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  4.10000000e+01,  4.96000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [ 1.67952800e-12,  4.60000000e+01,  3.80000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [-6.23021448e-13,  2.90000000e+01,  2.10000000e+04,\n",
       "        -2.03032656e-13],\n",
       "       ...,\n",
       "       [ 1.57996161e-12,  2.00000000e+01,  3.39000000e+04,\n",
       "         2.00000000e+00],\n",
       "       [ 1.00000000e+00,  2.20000000e+01,  3.27000000e+04,\n",
       "         3.00000000e+00],\n",
       "       [ 1.00000000e+00,  2.80000000e+01,  4.06000000e+04,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recover_X = trans_X@np.linalg.inv(P)\n",
    "recover_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can recover the original data from 𝑋′."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all three cases for a few customers\n",
    "- The original data\n",
    "- The transformed one\n",
    "- The reversed (recovered) one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 4.10e+01, 4.96e+04, 1.00e+00],\n",
       "       [0.00e+00, 4.60e+01, 3.80e+04, 1.00e+00],\n",
       "       [0.00e+00, 2.90e+01, 2.10e+04, 0.00e+00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6359.71527314, 22380.40467609, 18424.09074184, 46000.69669016],\n",
       "       [ 4873.29406479, 17160.36702982, 14125.78076133, 35253.45577301],\n",
       "       [ 2693.11742928,  9486.397744  ,  7808.83156024, 19484.86063067]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  4.10000000e+01,  4.96000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [ 1.67952800e-12,  4.60000000e+01,  3.80000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [-6.23021448e-13,  2.90000000e+01,  2.10000000e+04,\n",
       "        -2.03032656e-13]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recover_X[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can probably see that some values are not exactly the same as they are in the original data. What might be the reason for that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess it happens because numpy does some conversion to the original values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\t  \n",
    "This is due to limitations of floating point arithmetic\n",
    "\t  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof That Data Obfuscation Can Work with LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression task has been solved with linear regression in this project. Your next task is to prove _analytically_ that the given obfuscation method won't affect linear regression in terms of predicted values i.e. their values will remain the same. Can you believe that? Well, you don't have to, you should prove it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the data is obfuscated and there is $X \\times P$ instead of just $X$ now. Consequently, there are other weights $w_P$ as\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y \\quad \\Rightarrow \\quad w_P = [(XP)^T XP]^{-1} (XP)^T y\n",
    "$$\n",
    "\n",
    "How would $w$ and $w_P$ be linked if you simplify the formula for $w_P$ above? \n",
    "\n",
    "What would be predicted values with $w_P$? \n",
    "\n",
    "What does that mean for the quality of linear regression if you measure it with RMSE?\n",
    "\n",
    "Check Appendix B Properties of Matrices in the end of the notebook. There are useful formulas in there!\n",
    "\n",
    "No code is necessary in this section, only analytical explanation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below, the predicted values with $w$ and $w_P$ are same. Thus the RMSE is same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analytical proof**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ w = (X^T X)^{-1} X^T y $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ w_P = [(XP)^T XP]^{-1} (XP)^T y $$\n",
    "$$\\quad \\downarrow \\quad$$\n",
    "$$w_P = P^{-1}(X^TX)^{-1}(P^T)^{-1}P^TX^T y $$\n",
    "$$\\quad \\downarrow \\quad$$\n",
    "$$w_P = P^{-1}(X^TX)^{-1}X^T y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = Xw \\quad \\Rightarrow \\quad \\hat {y_P} = XPw_P \\quad \\Rightarrow \\quad \\hat {y_P} = XPP^{-1}w \\quad \\Rightarrow \\quad \\hat{y_P} = Xw\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<s><b>Reviewer's comment</b>\n",
    "\t  \n",
    "The proof is almost correct, just one small problem: as $X$ represents the feature matrix, its number of rows (examples) is much bigger than the number of columns (features), so the matrix is not even square, and thus can't be invertible. On the other hand, $X^T X$ is always square and it's invertible as long as the columns of $X$ are linearly independent. For this reason, $(X^T X)^{-1}$ can't be simplified any further, and should be left as is.\n",
    "    \n",
    "Other than that, you results are correct! Indeed, $w_P = P^{-1} w$ and the predictions of the original model and the model trained on obfuscated data will be exactly the same, and thus RMSE will also be the same.\n",
    "\t  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  Thanks for your comment! I hope it's okay now :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V2</b>\n",
    "\t  \n",
    "Yep, very good!\n",
    "\t  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Linear Regression With Data Obfuscation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's prove Linear Regression can work computationally with the chosen obfuscation transformation.\n",
    "\n",
    "Build a procedure or a class that runs Linear Regression optionally with the obfuscation. You can use either a ready implementation of Linear Regression from sciki-learn or your own.\n",
    "\n",
    "Run Linear Regression for the original data and the obfuscated one, compare the predicted values and the RMSE, $R^2$ metric values. Is there any difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedure**\n",
    "\n",
    "- Create a square matrix $P$ of random numbers.\n",
    "- Check that it is invertible. If not, repeat the first point until we get an invertible matrix.\n",
    "- <! your comment here !>\n",
    "- Use $XP$ as the new feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17926625,  0.80931996,  0.45614337, -0.23762191,  0.4650019 ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "display(y_pred[0:5])\n",
    "eval_regressor(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression with obfuscated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17926625,  0.80931996,  0.45614337, -0.23762191,  0.4650019 ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X_train.shape[1], X_train.shape[1]))\n",
    "P@np.linalg.inv(P)\n",
    "obfuscated_X = X@P\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(obfuscated_X, y, test_size=0.3, random_state=12345)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "display(y_pred[0:5])\n",
    "eval_regressor(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Obfuscation doesn't change the predicted values and the RMSE, 𝑅2 metric values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\t  \n",
    "Excellent! You empirically confirmed that our data obfuscation doesn't affect the model's quality\n",
    "\t  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 'x' to check. Then press Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook is open\n",
    "- [ ]  Code is error free\n",
    "- [ ]  The cells are arranged in order of logic and execution\n",
    "- [ ]  Task 1 has been performed\n",
    "    - [ ]  There is the procedure that can return k similar customers for a given one\n",
    "    - [ ]  The procedure is tested for all four proposed combinations\n",
    "    - [ ]  The questions re the scaling/distances are answered\n",
    "- [ ]  Task 2 has been performed\n",
    "    - [ ]  The random classification model is built and tested for all for probability levels\n",
    "    - [ ]  The kNN classification model is built and tested for both the original data and the scaled one, the F1 metric is calculated.\n",
    "- [ ]  Task 3 has been performed\n",
    "    - [ ]  The linear tegression solution is implemented with matrix operations.\n",
    "    - [ ]  RMSE is calculated for the implemented solution.\n",
    "- [ ]  Task 4 has been performed\n",
    "    - [ ]  The data is obfuscated with a random and invertible matrix P\n",
    "    - [ ]  The obfuscated data is recoved, few examples are printed out\n",
    "    - [ ]  The analytical proof that the transformation does not affect RMSE is provided \n",
    "    - [ ]  The computational proof that the transformation does not affect RMSE is provided\n",
    "- [ ]  Conclusions have been made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices \n",
    "\n",
    "## Appendix A: Writing Formulas in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write formulas in your Jupyter Notebook in a markup language provided by a high-quality publishing system called $\\LaTeX$ (pronounced \"Lah-tech\"), and they will look like formulas in textbooks.\n",
    "\n",
    "To put a formula in a text, put the dollar sign (\\\\$) before and after the formula's text e.g. $\\frac{1}{2} \\times \\frac{3}{2} = \\frac{3}{4}$ or $y = x^2, x \\ge 1$.\n",
    "\n",
    "If a formula should be in its own paragraph, put the double dollar sign (\\\\$\\\\$) before and after the formula text e.g.\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i.\n",
    "$$\n",
    "\n",
    "The markup language of [LaTeX](https://en.wikipedia.org/wiki/LaTeX) is very popular among people who use formulas in their articles, books and texts. It can be complex but its basics are easy. Check this two page [cheatsheet](http://tug.ctan.org/info/undergradmath/undergradmath.pdf) for learning how to compose the most common formulas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B: Properties of Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices have many properties in Linear Algebra. A few of them are listed here which can help with the analytical proof in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>Distributivity</td><td>$A(B+C)=AB+AC$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Non-commutativity</td><td>$AB \\neq BA$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Associative property of multiplication</td><td>$(AB)C = A(BC)$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Multiplicative identity property</td><td>$IA = AI = A$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td></td><td>$A^{-1}A = AA^{-1} = I$\n",
    "</td>\n",
    "</tr>    \n",
    "<tr>\n",
    "<td></td><td>$(AB)^{-1} = B^{-1}A^{-1}$</td>\n",
    "</tr>    \n",
    "<tr>\n",
    "<td>Reversivity of the transpose of a product of matrices,</td><td>$(AB)^T = B^TA^T$</td>\n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 11332,
    "start_time": "2021-11-03T18:27:51.342Z"
   },
   {
    "duration": 1542,
    "start_time": "2021-11-03T18:28:09.889Z"
   },
   {
    "duration": 58,
    "start_time": "2021-11-03T18:28:27.687Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-03T18:28:31.157Z"
   },
   {
    "duration": 17,
    "start_time": "2021-11-03T18:28:42.270Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-03T18:28:47.028Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-03T18:32:44.764Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-03T18:32:54.871Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-03T18:33:00.719Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-03T18:34:23.258Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-03T18:34:25.706Z"
   },
   {
    "duration": 35,
    "start_time": "2021-11-03T18:34:40.200Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-03T18:50:25.466Z"
   },
   {
    "duration": 97,
    "start_time": "2021-11-03T18:50:25.986Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-03T18:51:06.670Z"
   },
   {
    "duration": 16,
    "start_time": "2021-11-03T18:51:10.675Z"
   },
   {
    "duration": 16,
    "start_time": "2021-11-03T18:51:12.560Z"
   },
   {
    "duration": 8879,
    "start_time": "2021-11-04T10:16:26.158Z"
   },
   {
    "duration": 1542,
    "start_time": "2021-11-04T10:16:35.040Z"
   },
   {
    "duration": 19,
    "start_time": "2021-11-04T10:16:36.585Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T10:16:36.607Z"
   },
   {
    "duration": 36,
    "start_time": "2021-11-04T10:16:36.615Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-04T10:16:36.655Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T10:16:36.671Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-04T10:16:36.683Z"
   },
   {
    "duration": 53,
    "start_time": "2021-11-04T10:16:36.730Z"
   },
   {
    "duration": 9125,
    "start_time": "2021-11-04T10:16:36.786Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T10:16:45.913Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T10:16:45.928Z"
   },
   {
    "duration": 22,
    "start_time": "2021-11-04T10:16:45.935Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-04T10:16:45.960Z"
   },
   {
    "duration": 97,
    "start_time": "2021-11-04T10:16:45.976Z"
   },
   {
    "duration": 548,
    "start_time": "2021-11-04T10:21:43.507Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T10:23:00.208Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T10:23:12.484Z"
   },
   {
    "duration": 17,
    "start_time": "2021-11-04T10:25:26.749Z"
   },
   {
    "duration": 313,
    "start_time": "2021-11-04T10:47:27.139Z"
   },
   {
    "duration": 18,
    "start_time": "2021-11-04T10:48:39.297Z"
   },
   {
    "duration": 17,
    "start_time": "2021-11-04T10:50:51.953Z"
   },
   {
    "duration": 18,
    "start_time": "2021-11-04T10:52:56.692Z"
   },
   {
    "duration": 16,
    "start_time": "2021-11-04T10:53:04.604Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T10:54:53.666Z"
   },
   {
    "duration": 20,
    "start_time": "2021-11-04T10:55:09.454Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T10:59:55.017Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-04T11:08:08.509Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-04T11:09:23.965Z"
   },
   {
    "duration": 84,
    "start_time": "2021-11-04T11:09:36.227Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T11:09:46.029Z"
   },
   {
    "duration": 266,
    "start_time": "2021-11-04T11:09:57.783Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T11:10:09.349Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T11:10:48.649Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-04T11:14:03.948Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-04T11:14:11.360Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-04T11:14:20.304Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T11:14:47.841Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T11:14:53.711Z"
   },
   {
    "duration": 16,
    "start_time": "2021-11-04T11:15:58.078Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T11:16:02.903Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T11:16:22.162Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T11:16:29.213Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T11:18:16.511Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T11:18:26.766Z"
   },
   {
    "duration": 19,
    "start_time": "2021-11-04T11:18:34.004Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T11:18:36.840Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T11:18:39.190Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T11:19:33.512Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-04T11:19:37.862Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T11:19:40.511Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T11:19:42.552Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T11:28:05.645Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T11:28:29.402Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T11:29:10.473Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T11:29:15.611Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-04T11:29:33.807Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T11:33:12.479Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T11:33:50.843Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T11:34:41.889Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T11:34:51.140Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-04T11:38:07.141Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T11:38:12.753Z"
   },
   {
    "duration": 256,
    "start_time": "2021-11-04T11:57:00.130Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T11:57:40.856Z"
   },
   {
    "duration": 6258,
    "start_time": "2021-11-04T12:03:37.564Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-04T12:08:38.977Z"
   },
   {
    "duration": 19,
    "start_time": "2021-11-04T12:08:46.699Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-04T12:49:13.331Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T12:57:26.129Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-04T12:57:39.623Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T12:57:45.842Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T13:16:07.773Z"
   },
   {
    "duration": 273,
    "start_time": "2021-11-04T13:16:07.785Z"
   },
   {
    "duration": -70,
    "start_time": "2021-11-04T13:16:08.131Z"
   },
   {
    "duration": -94,
    "start_time": "2021-11-04T13:16:08.156Z"
   },
   {
    "duration": -105,
    "start_time": "2021-11-04T13:16:08.168Z"
   },
   {
    "duration": -127,
    "start_time": "2021-11-04T13:16:08.192Z"
   },
   {
    "duration": -137,
    "start_time": "2021-11-04T13:16:08.203Z"
   },
   {
    "duration": -157,
    "start_time": "2021-11-04T13:16:08.224Z"
   },
   {
    "duration": -177,
    "start_time": "2021-11-04T13:16:08.245Z"
   },
   {
    "duration": -194,
    "start_time": "2021-11-04T13:16:08.264Z"
   },
   {
    "duration": -211,
    "start_time": "2021-11-04T13:16:08.282Z"
   },
   {
    "duration": -233,
    "start_time": "2021-11-04T13:16:08.305Z"
   },
   {
    "duration": -240,
    "start_time": "2021-11-04T13:16:08.314Z"
   },
   {
    "duration": -253,
    "start_time": "2021-11-04T13:16:08.328Z"
   },
   {
    "duration": -266,
    "start_time": "2021-11-04T13:16:08.342Z"
   },
   {
    "duration": -278,
    "start_time": "2021-11-04T13:16:08.355Z"
   },
   {
    "duration": -284,
    "start_time": "2021-11-04T13:16:08.363Z"
   },
   {
    "duration": -300,
    "start_time": "2021-11-04T13:16:08.380Z"
   },
   {
    "duration": -311,
    "start_time": "2021-11-04T13:16:08.392Z"
   },
   {
    "duration": -323,
    "start_time": "2021-11-04T13:16:08.406Z"
   },
   {
    "duration": -329,
    "start_time": "2021-11-04T13:16:08.413Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T13:16:57.673Z"
   },
   {
    "duration": 311,
    "start_time": "2021-11-04T13:17:00.393Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T13:17:17.278Z"
   },
   {
    "duration": 286,
    "start_time": "2021-11-04T13:17:18.457Z"
   },
   {
    "duration": 3897,
    "start_time": "2021-11-04T13:18:21.706Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T13:18:25.607Z"
   },
   {
    "duration": 25,
    "start_time": "2021-11-04T13:18:25.616Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:18:25.644Z"
   },
   {
    "duration": 16,
    "start_time": "2021-11-04T13:18:25.652Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T13:18:25.670Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:18:25.681Z"
   },
   {
    "duration": 40,
    "start_time": "2021-11-04T13:18:25.689Z"
   },
   {
    "duration": 33,
    "start_time": "2021-11-04T13:18:25.732Z"
   },
   {
    "duration": 8784,
    "start_time": "2021-11-04T13:18:25.767Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-04T13:18:34.553Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T13:18:34.558Z"
   },
   {
    "duration": 18,
    "start_time": "2021-11-04T13:18:34.568Z"
   },
   {
    "duration": 13,
    "start_time": "2021-11-04T13:18:34.588Z"
   },
   {
    "duration": 28,
    "start_time": "2021-11-04T13:18:34.603Z"
   },
   {
    "duration": 19,
    "start_time": "2021-11-04T13:18:34.633Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T13:18:34.654Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-04T13:18:34.662Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T13:18:34.673Z"
   },
   {
    "duration": 61,
    "start_time": "2021-11-04T13:18:34.682Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-04T13:18:34.746Z"
   },
   {
    "duration": 18,
    "start_time": "2021-11-04T13:18:34.757Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:19:56.752Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:20:15.245Z"
   },
   {
    "duration": 99,
    "start_time": "2021-11-04T13:22:47.473Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T13:22:55.230Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:23:21.544Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:24:22.468Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T13:24:27.812Z"
   },
   {
    "duration": 21,
    "start_time": "2021-11-04T13:35:09.104Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-04T13:35:09.128Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:35:09.143Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T13:35:09.150Z"
   },
   {
    "duration": 93,
    "start_time": "2021-11-04T13:35:09.158Z"
   },
   {
    "duration": -79,
    "start_time": "2021-11-04T13:35:09.333Z"
   },
   {
    "duration": -91,
    "start_time": "2021-11-04T13:35:09.346Z"
   },
   {
    "duration": -106,
    "start_time": "2021-11-04T13:35:09.362Z"
   },
   {
    "duration": -121,
    "start_time": "2021-11-04T13:35:09.379Z"
   },
   {
    "duration": -128,
    "start_time": "2021-11-04T13:35:09.387Z"
   },
   {
    "duration": -151,
    "start_time": "2021-11-04T13:35:09.412Z"
   },
   {
    "duration": -163,
    "start_time": "2021-11-04T13:35:09.425Z"
   },
   {
    "duration": -172,
    "start_time": "2021-11-04T13:35:09.435Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:38:47.934Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T13:42:23.086Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T13:42:48.834Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-04T13:42:55.221Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-04T13:43:17.473Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-04T13:43:35.700Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-04T13:43:41.892Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-04T13:43:50.825Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-04T13:44:04.601Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T13:44:25.739Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T13:44:42.526Z"
   },
   {
    "duration": 24,
    "start_time": "2021-11-04T13:49:16.605Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-04T13:52:55.246Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:53:36.638Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:54:22.073Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T13:54:33.988Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:54:53.841Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T13:55:52.435Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T13:58:54.860Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T13:59:14.074Z"
   },
   {
    "duration": 250,
    "start_time": "2021-11-04T14:08:27.489Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T14:08:35.376Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T14:08:41.614Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T14:08:54.174Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T14:08:59.891Z"
   },
   {
    "duration": 265,
    "start_time": "2021-11-04T14:11:23.776Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T14:11:30.903Z"
   },
   {
    "duration": 493,
    "start_time": "2021-11-04T14:11:32.031Z"
   },
   {
    "duration": 56,
    "start_time": "2021-11-04T14:13:13.683Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-04T15:46:23.667Z"
   },
   {
    "duration": 94,
    "start_time": "2021-11-04T15:47:08.986Z"
   },
   {
    "duration": 105,
    "start_time": "2021-11-04T15:47:44.329Z"
   },
   {
    "duration": 92,
    "start_time": "2021-11-04T15:50:35.925Z"
   },
   {
    "duration": 100,
    "start_time": "2021-11-04T15:50:53.902Z"
   },
   {
    "duration": 334,
    "start_time": "2021-11-04T15:53:06.418Z"
   },
   {
    "duration": 101,
    "start_time": "2021-11-04T15:53:29.528Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-04T15:54:36.683Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T15:54:44.790Z"
   },
   {
    "duration": 101,
    "start_time": "2021-11-04T15:55:00.419Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-04T15:55:08.077Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-04T15:55:14.998Z"
   },
   {
    "duration": 359,
    "start_time": "2021-11-04T15:56:30.870Z"
   },
   {
    "duration": 958,
    "start_time": "2021-11-04T15:56:40.392Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T17:23:05.228Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-04T17:23:06.232Z"
   },
   {
    "duration": 970,
    "start_time": "2021-11-04T17:23:07.381Z"
   },
   {
    "duration": 36,
    "start_time": "2021-11-04T17:28:56.096Z"
   },
   {
    "duration": 33,
    "start_time": "2021-11-04T17:29:23.935Z"
   },
   {
    "duration": 269,
    "start_time": "2021-11-04T17:30:30.030Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-04T17:31:22.328Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-04T17:31:38.121Z"
   },
   {
    "duration": 950,
    "start_time": "2021-11-04T17:32:09.525Z"
   },
   {
    "duration": 11709,
    "start_time": "2021-11-06T12:47:53.707Z"
   },
   {
    "duration": 1657,
    "start_time": "2021-11-06T12:48:05.420Z"
   },
   {
    "duration": 21,
    "start_time": "2021-11-06T12:48:07.081Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T12:48:07.106Z"
   },
   {
    "duration": 33,
    "start_time": "2021-11-06T12:48:07.116Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-06T12:48:07.152Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T12:48:07.166Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-06T12:48:07.204Z"
   },
   {
    "duration": 33,
    "start_time": "2021-11-06T12:48:07.222Z"
   },
   {
    "duration": 8726,
    "start_time": "2021-11-06T12:48:07.257Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-06T12:48:15.985Z"
   },
   {
    "duration": 13,
    "start_time": "2021-11-06T12:48:16.002Z"
   },
   {
    "duration": 31,
    "start_time": "2021-11-06T12:48:16.017Z"
   },
   {
    "duration": 21,
    "start_time": "2021-11-06T12:48:16.050Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T12:48:16.073Z"
   },
   {
    "duration": 36,
    "start_time": "2021-11-06T12:48:16.083Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-06T12:48:16.122Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-06T12:48:16.134Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T12:48:16.149Z"
   },
   {
    "duration": 44,
    "start_time": "2021-11-06T12:48:16.158Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T12:48:16.205Z"
   },
   {
    "duration": 18,
    "start_time": "2021-11-06T12:48:16.214Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-06T12:48:16.238Z"
   },
   {
    "duration": 64,
    "start_time": "2021-11-06T12:48:16.250Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-06T12:48:16.317Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-06T12:48:16.334Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T12:48:16.341Z"
   },
   {
    "duration": 90,
    "start_time": "2021-11-06T12:48:16.349Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T12:48:16.441Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-06T12:48:16.449Z"
   },
   {
    "duration": 980,
    "start_time": "2021-11-06T12:48:16.462Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-06T12:48:17.445Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-06T12:48:17.452Z"
   },
   {
    "duration": 1272,
    "start_time": "2021-11-06T12:48:17.466Z"
   },
   {
    "duration": 545,
    "start_time": "2021-11-06T13:15:20.074Z"
   },
   {
    "duration": 366,
    "start_time": "2021-11-06T13:15:51.961Z"
   },
   {
    "duration": 5523,
    "start_time": "2021-11-06T13:15:58.917Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:16:04.443Z"
   },
   {
    "duration": 22,
    "start_time": "2021-11-06T13:16:04.453Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:16:04.478Z"
   },
   {
    "duration": 16,
    "start_time": "2021-11-06T13:16:04.486Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-06T13:16:04.504Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-06T13:16:04.517Z"
   },
   {
    "duration": 88,
    "start_time": "2021-11-06T13:16:04.526Z"
   },
   {
    "duration": 59,
    "start_time": "2021-11-06T13:16:04.617Z"
   },
   {
    "duration": 8862,
    "start_time": "2021-11-06T13:16:04.679Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-06T13:16:13.544Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-06T13:16:13.550Z"
   },
   {
    "duration": 40,
    "start_time": "2021-11-06T13:16:13.561Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-06T13:16:13.604Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-06T13:16:13.621Z"
   },
   {
    "duration": 16,
    "start_time": "2021-11-06T13:16:13.633Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:16:13.652Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-06T13:16:13.702Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:16:13.714Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-06T13:16:13.722Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:16:13.740Z"
   },
   {
    "duration": 55,
    "start_time": "2021-11-06T13:16:13.749Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:16:13.812Z"
   },
   {
    "duration": 37,
    "start_time": "2021-11-06T13:16:13.822Z"
   },
   {
    "duration": 47,
    "start_time": "2021-11-06T13:16:13.862Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:16:13.912Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:16:13.921Z"
   },
   {
    "duration": 92,
    "start_time": "2021-11-06T13:16:13.930Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:16:14.024Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-06T13:16:14.033Z"
   },
   {
    "duration": 907,
    "start_time": "2021-11-06T13:16:14.043Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-06T13:16:14.952Z"
   },
   {
    "duration": 43,
    "start_time": "2021-11-06T13:16:14.959Z"
   },
   {
    "duration": 1037,
    "start_time": "2021-11-06T13:16:15.005Z"
   },
   {
    "duration": 376,
    "start_time": "2021-11-06T13:16:16.044Z"
   },
   {
    "duration": 409,
    "start_time": "2021-11-06T13:16:55.310Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-06T13:17:03.192Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T13:17:07.920Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-06T13:17:11.487Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T13:19:22.087Z"
   },
   {
    "duration": 825,
    "start_time": "2021-11-06T13:20:06.900Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T13:25:51.244Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-06T13:25:51.825Z"
   },
   {
    "duration": 935,
    "start_time": "2021-11-06T13:25:54.616Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:27:11.354Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-06T13:27:12.565Z"
   },
   {
    "duration": 880,
    "start_time": "2021-11-06T13:27:13.333Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T13:28:11.496Z"
   },
   {
    "duration": 16,
    "start_time": "2021-11-06T13:28:18.729Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-06T13:30:18.110Z"
   },
   {
    "duration": 470,
    "start_time": "2021-11-06T13:53:51.654Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-06T13:54:08.242Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-06T13:54:08.578Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-06T13:54:09.491Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T13:54:10.371Z"
   },
   {
    "duration": 373,
    "start_time": "2021-11-06T13:54:33.241Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T13:58:07.313Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-06T13:59:02.497Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T14:00:46.326Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-06T14:02:31.228Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T14:02:36.928Z"
   },
   {
    "duration": 369,
    "start_time": "2021-11-06T14:03:06.363Z"
   },
   {
    "duration": 405,
    "start_time": "2021-11-06T14:04:34.287Z"
   },
   {
    "duration": 384,
    "start_time": "2021-11-06T14:05:16.148Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T14:05:22.549Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T14:05:59.663Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-06T14:07:10.933Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-06T14:09:23.278Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-06T14:09:53.888Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T14:10:07.510Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T14:10:27.843Z"
   },
   {
    "duration": 395,
    "start_time": "2021-11-06T14:10:37.553Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T14:10:41.960Z"
   },
   {
    "duration": 134,
    "start_time": "2021-11-06T20:10:50.692Z"
   },
   {
    "duration": 11905,
    "start_time": "2021-11-06T20:13:53.115Z"
   },
   {
    "duration": 1572,
    "start_time": "2021-11-06T20:14:05.023Z"
   },
   {
    "duration": 20,
    "start_time": "2021-11-06T20:14:06.598Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-06T20:14:06.621Z"
   },
   {
    "duration": 19,
    "start_time": "2021-11-06T20:14:06.635Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-06T20:14:06.657Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-06T20:14:06.667Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-06T20:14:06.679Z"
   },
   {
    "duration": 34,
    "start_time": "2021-11-06T20:14:06.690Z"
   },
   {
    "duration": 7858,
    "start_time": "2021-11-06T20:14:06.759Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-06T20:14:14.620Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T20:14:14.626Z"
   },
   {
    "duration": 34,
    "start_time": "2021-11-06T20:14:14.634Z"
   },
   {
    "duration": 13,
    "start_time": "2021-11-06T20:14:14.670Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T20:14:14.685Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-06T20:14:14.693Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T20:14:14.709Z"
   },
   {
    "duration": 48,
    "start_time": "2021-11-06T20:14:14.717Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-06T20:14:14.767Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-06T20:14:14.782Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T20:14:14.799Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-06T20:14:14.807Z"
   },
   {
    "duration": 42,
    "start_time": "2021-11-06T20:14:14.819Z"
   },
   {
    "duration": 33,
    "start_time": "2021-11-06T20:14:14.864Z"
   },
   {
    "duration": 15,
    "start_time": "2021-11-06T20:14:14.899Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-06T20:14:14.916Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-06T20:14:14.959Z"
   },
   {
    "duration": 54,
    "start_time": "2021-11-06T20:14:14.966Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-06T20:14:15.022Z"
   },
   {
    "duration": 37,
    "start_time": "2021-11-06T20:14:15.029Z"
   },
   {
    "duration": 814,
    "start_time": "2021-11-06T20:14:15.069Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-06T20:14:15.885Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-06T20:14:15.892Z"
   },
   {
    "duration": 1171,
    "start_time": "2021-11-06T20:14:15.904Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T20:14:17.077Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-06T20:14:17.085Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-06T20:14:17.098Z"
   },
   {
    "duration": 103,
    "start_time": "2021-11-06T20:14:17.162Z"
   },
   {
    "duration": 91,
    "start_time": "2021-11-06T20:14:17.269Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-06T20:14:17.363Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-06T20:14:17.373Z"
   },
   {
    "duration": 74,
    "start_time": "2021-11-06T20:14:17.388Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-06T20:14:17.465Z"
   },
   {
    "duration": 85,
    "start_time": "2021-11-06T20:14:17.476Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-06T20:14:17.564Z"
   },
   {
    "duration": 86,
    "start_time": "2021-11-06T20:14:17.576Z"
   },
   {
    "duration": 94,
    "start_time": "2021-11-06T20:14:17.665Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-06T20:14:17.762Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-06T20:27:12.908Z"
   },
   {
    "duration": 7779,
    "start_time": "2021-11-07T07:24:28.971Z"
   },
   {
    "duration": 1372,
    "start_time": "2021-11-07T07:24:36.752Z"
   },
   {
    "duration": 20,
    "start_time": "2021-11-07T07:24:38.126Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-07T07:24:38.148Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-07T07:24:38.154Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T07:24:38.168Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T07:24:38.175Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-07T07:24:38.183Z"
   },
   {
    "duration": 21,
    "start_time": "2021-11-07T07:24:38.193Z"
   },
   {
    "duration": 4999,
    "start_time": "2021-11-07T07:24:38.216Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-07T07:24:43.217Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T07:24:43.221Z"
   },
   {
    "duration": 23,
    "start_time": "2021-11-07T07:24:43.228Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-07T07:24:43.252Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T07:24:43.263Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-07T07:24:43.270Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T07:24:43.283Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-07T07:24:43.290Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T07:24:43.300Z"
   },
   {
    "duration": 44,
    "start_time": "2021-11-07T07:24:43.306Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T07:24:43.352Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T07:24:43.358Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T07:24:43.367Z"
   },
   {
    "duration": 27,
    "start_time": "2021-11-07T07:24:43.374Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-07T07:24:43.403Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-07T07:24:43.445Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T07:24:43.450Z"
   },
   {
    "duration": 41,
    "start_time": "2021-11-07T07:24:43.456Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-07T07:24:43.499Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-07T07:24:43.504Z"
   },
   {
    "duration": 511,
    "start_time": "2021-11-07T07:24:43.513Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-07T07:24:44.026Z"
   },
   {
    "duration": 13,
    "start_time": "2021-11-07T07:24:44.031Z"
   },
   {
    "duration": 659,
    "start_time": "2021-11-07T07:24:44.046Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T07:24:44.707Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-07T07:24:44.713Z"
   },
   {
    "duration": 19,
    "start_time": "2021-11-07T07:24:44.726Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-07T07:24:44.747Z"
   },
   {
    "duration": 92,
    "start_time": "2021-11-07T07:24:44.758Z"
   },
   {
    "duration": 91,
    "start_time": "2021-11-07T07:24:44.853Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-07T07:24:44.946Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-07T07:24:44.951Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T07:24:44.961Z"
   },
   {
    "duration": 76,
    "start_time": "2021-11-07T07:24:44.969Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T07:24:45.047Z"
   },
   {
    "duration": 95,
    "start_time": "2021-11-07T07:24:45.054Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T07:24:45.151Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T07:24:45.159Z"
   },
   {
    "duration": 166,
    "start_time": "2021-11-07T07:24:45.166Z"
   },
   {
    "duration": -58,
    "start_time": "2021-11-07T07:24:45.392Z"
   },
   {
    "duration": 88,
    "start_time": "2021-11-07T08:26:28.147Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-07T11:29:47.273Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-07T11:29:56.088Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-07T11:36:30.486Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T11:48:31.900Z"
   },
   {
    "duration": 744,
    "start_time": "2021-11-07T11:51:56.574Z"
   },
   {
    "duration": 557,
    "start_time": "2021-11-07T11:54:24.768Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-07T11:58:15.848Z"
   },
   {
    "duration": 514,
    "start_time": "2021-11-07T11:58:28.814Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-07T11:59:40.404Z"
   },
   {
    "duration": 689,
    "start_time": "2021-11-07T12:00:01.689Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-07T12:07:05.883Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-07T12:07:08.080Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-07T12:08:22.525Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T12:12:48.412Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-07T12:12:49.386Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-07T12:13:20.525Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-07T12:13:22.496Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T12:13:30.929Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-07T12:13:31.595Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T12:13:40.568Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-07T12:13:41.215Z"
   },
   {
    "duration": 269,
    "start_time": "2021-11-07T12:13:49.867Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-07T12:13:59.487Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T12:18:50.089Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T12:18:53.033Z"
   },
   {
    "duration": 629,
    "start_time": "2021-11-07T12:19:01.111Z"
   },
   {
    "duration": 554,
    "start_time": "2021-11-07T12:19:42.125Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-07T12:24:02.553Z"
   },
   {
    "duration": 588,
    "start_time": "2021-11-07T12:24:10.213Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-07T12:25:38.347Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-07T12:25:45.766Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T12:25:49.001Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-07T12:25:51.269Z"
   },
   {
    "duration": 6,
    "start_time": "2021-11-07T12:26:56.927Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-07T12:27:06.645Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-07T12:27:26.896Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-07T12:27:31.702Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-07T12:31:10.572Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-07T12:31:23.457Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-07T12:46:53.770Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-07T12:53:37.746Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "335px",
    "width": "396px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
